#!/bin/bash
# usage: run-nextclade-full --database=gisaid|genbank [--jobs]
#        run-nextclade-full --help
#
# Make a full Nextclade run, recomputing clades and other metrics
# for all sequences. This is necessary every time when new clades are defined or
# when upgrading to the new version of Nextclade with breaking changes.

# Note: this might take very long time to run (hours to days), depending on
# number of sequences to be processed and available computational resources.
#
# --database=gisaid|genbank   Database to use. This defines which sequences will
#                             be downloaded and where the results will be
#                             uploaded.
#
# --jobs                      Maximum number of threads Nextclade is allowed to
#                             use.

set -euo pipefail
trap "exit" INT

disk_info() {
  echo "[ INFO] ${0}:${LINENO}: Summary of block devices:"
  lsblk -o MOUNTPOINT,FSSIZE,FSAVAIL,TYPE,NAME,ROTA,SIZE,MODEL || true

  echo "[ INFO] ${0}:${LINENO}: Summary of disk space usage:"
  df -Th || true | awk 'NR == 1; NR > 1 {print $0 | "sort -n"}'

  echo "[ INFO] ${0}:${LINENO}: Summary of occupied disk space:"
  du -bsch ./* 2>/dev/null || true | sort -h
}

main() {
  # Total number of processors in the system that Nextclade can use.
  # Default equals to the number of threads on all CPUs combined.
  N_PROCESSORS=${N_PROCESSORS:-$(getconf _NPROCESSORS_ONLN)}

  DATABASE=

  silent=0

  for arg; do
    case "$arg" in
    -h | --help)
      print-help
      exit
      ;;
    --database=*)
      DATABASE="${arg#*=}"
      shift
      ;;
    --jobs=*)
      N_PROCESSORS="${arg#*=}"
      shift
      ;;
    esac
  done

  if [ "${DATABASE}" == "gisaid" ]; then
    S3_SRC="s3://nextstrain-ncov-private"
  elif [ "${DATABASE}" == "genbank" ]; then
    S3_SRC="s3://nextstrain-data/files/ncov/open"
  elif [ "${DATABASE}" == "rki" ]; then
    S3_SRC="s3://nextstrain-data/files/ncov/rki"
  else
    echo "[ERROR] ${0}:${LINENO}: Unknown database: The '--database' flag should be set to either 'gisaid' or 'genbank'"
    exit 1
  fi

  DATE_UTC=$(date -u "+%Y-%m-%d--%H-%M-%S--%Z")
  S3_DST="$S3_SRC/nextclade-full-run-${DATE_UTC}"

  INPUT_FASTA="data/${DATABASE}/sequences.fasta.zst"
  OUTPUT_FASTA="data/${DATABASE}/aligned.fasta"
  OUTPUT_TSV="data/${DATABASE}/nextclade.tsv"

  TMP_DIR_NEXTCLADE_DATASET="tmp/dataset"

  NEXTCLADE_BIN_URL="https://github.com/nextstrain/nextclade/releases/latest/download/nextclade-x86_64-unknown-linux-gnu"
  NEXTCLADE_BIN="./nextclade"

  GENES=E,M,N,ORF1a,ORF1b,ORF3a,ORF6,ORF7a,ORF7b,ORF8,ORF9b,S

  echo "[ INFO] ${0}:${LINENO}: Nextclade full run is starting"
  echo "[ INFO] ${0}:${LINENO}:   DATABASE=${DATABASE}"
  echo "[ INFO] ${0}:${LINENO}:   N_PROCESSORS=${N_PROCESSORS}"
  echo "[ INFO] ${0}:${LINENO}:   S3_SRC=${S3_SRC}"
  echo "[ INFO] ${0}:${LINENO}:   S3_DST=${S3_DST}"
  echo "[ INFO] ${0}:${LINENO}:   NEXTCLADE_BIN_URL=${NEXTCLADE_BIN_URL}"

  disk_info

  ./bin/notify-on-job-start "ü¶¨ 'Nextclade full run: ${DATABASE}'" "The job involves ${N_PROCESSORS} CPUs. The results will be uploaded to \`${S3_DST}\`. Someone needs to inspect these results and then copy them over to the S3 directory where the next scheduled ingest can find them, replacing the old files. For more details, see https://github.com/nextstrain/ncov-ingest/pull/218 ."

  if [ ! -f "${NEXTCLADE_BIN}" ]; then
    echo "[ INFO] ${0}:${LINENO}: Downloading latest Nextclade version from '${NEXTCLADE_BIN_URL}' to '${NEXTCLADE_BIN}'"
    curl -fsSL ${NEXTCLADE_BIN_URL} -o "${NEXTCLADE_BIN}"
    chmod +x "${NEXTCLADE_BIN}"
  else
    echo "[ INFO] ${0}:${LINENO}: ‚ö†Ô∏èUsing existing Nextclade binary '${NEXTCLADE_BIN}' from the working directory. Skipping downloading the latest version. If this was not intended, cancel this run, remove '${NEXTCLADE_BIN}' from your working directory and rerun."
  fi

  if ! command -v ./${NEXTCLADE_BIN} &>/dev/null; then
    echo "[ERROR] ${0}:${LINENO}: Nextclade executable not found"
    exit 1
  fi

  echo "[ INFO] ${0}:${LINENO}: Downloading '${S3_SRC}/sequences.fasta.zst' to '${INPUT_FASTA}'"
  aws s3 cp --no-progress "${S3_SRC}/sequences.fasta.xz" "${INPUT_FASTA}"

  NEXTCLADE_VERSION="$(./${NEXTCLADE_BIN} --version)"
  echo "[ INFO] ${0}:${LINENO}: Nextclade version: ${NEXTCLADE_VERSION}"

  if [ ! -f "${TMP_DIR_NEXTCLADE_DATASET}/tree.json" ] || [ ! -f "${TMP_DIR_NEXTCLADE_DATASET}/reference.fasta" ]; then
    echo "[ INFO] ${0}:${LINENO}: Downloading Nextclade dataset \"sars-cov-2\" into '${TMP_DIR_NEXTCLADE_DATASET}'"
    "${NEXTCLADE_BIN}" dataset get --name="sars-cov-2" --output-dir="${TMP_DIR_NEXTCLADE_DATASET}" --verbose
  else
    echo "[ INFO] ${0}:${LINENO}: ‚ö†Ô∏èUsing existing Nextclade dataset '${TMP_DIR_NEXTCLADE_DATASET}' from the working directory. Skipping downloading the latest dataset. If this was not intended, cancel this run, remove '${TMP_DIR_NEXTCLADE_DATASET}' from your working directory and rerun."
  fi

  echo "[ INFO] ${0}:${LINENO}: Nextclade is allowed to use ${N_PROCESSORS} threads."

  "${NEXTCLADE_BIN}" run \
    "${INPUT_FASTA}" \
    --jobs="${N_PROCESSORS}" \
    --in-order \
    --verbosity=error \
    --input-dataset="${TMP_DIR_NEXTCLADE_DATASET}" \
    --genes="${GENES}" \
    --output-tsv="${OUTPUT_TSV}" \
    --output-fasta="${OUTPUT_FASTA}"

  echo "[ INFO] ${0}:${LINENO}: Upload results"
  ./bin/upload-to-s3 ${silent:+--quiet} "${OUTPUT_TSV}" "$S3_DST/nextclade.tsv.gz"
  ./bin/upload-to-s3 ${silent:+--quiet} "${OUTPUT_FASTA}" "$S3_DST/aligned.fasta.xz"

  # Parallel uploads of zstd compressed files to slowly transition to this format
  ./bin/upload-to-s3 ${silent:+--quiet} "${OUTPUT_TSV}" "$S3_DST/nextclade.tsv.zst"
  ./bin/upload-to-s3 ${silent:+--quiet} "${OUTPUT_FASTA}" "$S3_DST/aligned.fasta.zst"

  # Cut the running time by deleting working directory and avoiding zipping it.
  # We are unlikely to inspect it anyways. But keep the TSV result file, just in
  # case.
  mv "${OUTPUT_TSV}" "nextclade.tsv"
  rm -rf data tmp "${NEXTCLADE_BIN}"
  mkdir -p "$(dirname "${OUTPUT_TSV}")"
  mv "nextclade.tsv" "${OUTPUT_TSV}"
}

print-help() {
  # Print the help comments at the top of this file ($0)
  local line
  while read -r line; do
    if [[ $line =~ ^#! ]]; then
      continue
    elif [[ $line =~ ^# ]]; then
      line="${line/##/}"
      line="${line/# /}"
      echo "$line"
    else
      break
    fi
  done <"$0"
}

main "$@"
