#!/usr/bin/env python3
"""
Deduplicate records by GISAID EPI ISL.
Only keeps the first record of duplicates.
"""
import argparse
from sys import stdin
from typing import Iterable
from augur.io.json import dump_ndjson, load_ndjson
from augur.io.print import print_err


def deduplicate_records(records: Iterable[dict],
                        id_field: str) -> Iterable:
    """
    Deduplicate *records* by *id_field*, will only keeping the first record of
    duplicate ids.

    Yields records with unique ids.
    """
    seen_ids = set()
    for index, record in enumerate(records):
        record_id = record.get(id_field)

        if record_id is None:
            raise Exception(f"Records must have the expected id field {id_field!r}")

        if record_id in seen_ids:
            print_err(
                f"Dropping record (index {index!r}) with duplicate record id {record_id!r}"
            )
            continue

        seen_ids.add(record_id)
        yield record


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)

    parser.add_argument("--id-field", default="gisaid_epi_isl",
        help="The record field containing a record id. ")

    args = parser.parse_args()

    records = load_ndjson(stdin)
    deduped_records = deduplicate_records(records, args.id_field)
    dump_ndjson(deduped_records)
