#!/bin/bash
# usage: ingest-gisaid [--fetch]
#        ingest-gisaid --help
#
# Ingest SARS-CoV-2 metadata and sequences from GISAID.
#
# If the --fetch flag is given, new records are fetched from GISAID. Otherwise,
# ingest from the existing GISAID NDJSON file on S3.
#
set -euo pipefail

: "${S3_SRC:=s3://nextstrain-ncov-private}"
: "${S3_DST:=$S3_SRC}"

main() {
    local fetch=0

    for arg; do
        case "$arg" in
            -h|--help)
                print-help
                exit
                ;;
            --fetch)
                fetch=1
                shift
                break
                ;;
        esac
    done

    # Determine where to save data files based on if we're running as a result of a
    # push to master or to another branch (or locally, outside of the GitHub
    # workflow).  Files are always compared to the default/primary paths in the
    # source S3 bucket.
    #
    local silent=
    local branch=

    case "${GITHUB_REF:-}" in
        refs/heads/master)
            # Do nothing different; defaults above are good.
            branch=master
            ;;
        refs/heads/*)
            # Save data files under a per-branch prefix
            silent=yes
            branch="${GITHUB_REF##refs/heads/}"
            S3_DST="$S3_DST/branch/$branch"
            ;;
        "")
            # Save data files under a tmp prefix
            silent=yes
            S3_DST="$S3_DST/tmp"
            ;;
        *)
            echo "Skipping ingest for ref $GITHUB_REF"
            exit 0
            ;;
    esac

    echo "S3_SRC is $S3_SRC"
    echo "S3_DST is $S3_DST"

    cd "$(dirname "$0")/.."

    if [[ "$branch" == master ]]; then
      ./bin/notify-on-job-start "ðŸ¥— GISAID ingest"
    fi

    if [[ "$fetch" == 1 ]]; then
        local attempt=0 max_attempts=5

        while [[ $((++attempt)) -le $max_attempts ]]; do
            echo "Fetch attempt $attempt"
            if ./bin/fetch-from-gisaid > data/gisaid.ndjson; then
                break
            else
                echo "...FAILED"
                rm data/gisaid.ndjson
                sleep 10
            fi
        done
        if [[ ! -f data/gisaid.ndjson ]]; then
            echo "Failed to fetch"
            exit 1
        fi
        if [[ "$branch" == master ]]; then
            ./bin/notify-on-record-change data/gisaid.ndjson "$S3_SRC/gisaid.ndjson.xz" "GISAID"
        fi
        ./bin/upload-to-s3 --quiet data/gisaid.ndjson "$S3_DST/gisaid.ndjson.xz"
    else
        ./bin/download-from-s3 "$S3_DST/gisaid.ndjson.xz" "data/gisaid.ndjson"
    fi

    flagged_annotations="$(mktemp -t flagged-annotations-XXXXXX)"
    trap "rm -f '$flagged_annotations'" EXIT
    ./bin/transform-gisaid data/gisaid.ndjson \
        --output-metadata data/gisaid/metadata.tsv \
        --output-fasta data/gisaid/sequences.fasta \
        --output-unix-newline > "$flagged_annotations"

    # Remove gisaid.ndjson to save disk space.
    rm data/gisaid.ndjson

    # Download old clades
    ./bin/download-from-s3 "$S3_DST/nextclade.tsv.gz" "data/gisaid/nextclade_old.tsv" ||  \
    ./bin/download-from-s3 "$S3_SRC/nextclade.tsv.gz" "data/gisaid/nextclade_old.tsv"

    # Find sequences in FASTA which don't have clades assigned yet
    ./bin/filter-fasta \
      --input_fasta="data/gisaid/sequences.fasta" \
      --input_tsv="data/gisaid/nextclade_old.tsv" \
      --output_fasta="data/gisaid/nextclade.sequences.fasta" \

    # Check if the file with these extracted sequences is not empty
    if [ ! -s "data/gisaid/nextclade.sequences.fasta" ]; then
       echo "[ INFO] ${0}:${LINENO}: No new sequences for Nextclade to process. Skipping."
       mv data/gisaid/nextclade_old.tsv data/gisaid/nextclade.tsv
    else

      # And if it's not empty, run nextclade analysis on these sequences,
      # to assign clades and calculate other useful metrics
      ./bin/run-nextclade \
        "data/gisaid/nextclade.sequences.fasta" \
        "data/gisaid/nextclade_new.tsv" \
        "data/gisaid/nextclade-inputs" \
        "data/gisaid/nextclade" \
        "data/gisaid/nextclade.aligned.new.fasta"

      # Join new and old clades, so that next run won't need to process sequences that are already processed
      ./bin/join-rows \
        "data/gisaid/nextclade_old.tsv" \
        "data/gisaid/nextclade_new.tsv" \
        -o "data/gisaid/nextclade.tsv"

      # Download old alignment
      ./bin/download-from-s3 "$S3_DST/nextclade.aligned.fasta.xz" "data/gisaid/nextclade.aligned.old.fasta"

      # Join new and old alignment
      cat "data/gisaid/nextclade.aligned.old.fasta" \
          "data/gisaid/nextclade.aligned.new.fasta" \
         >"data/gisaid/nextclade.aligned.fasta"

    fi

    # Join clades and analysis results into metadata
    ./bin/join-metadata-and-clades \
      "data/gisaid/metadata.tsv" \
      "data/gisaid/nextclade.tsv" \
      -o "data/gisaid/metadata.tsv"

    ./bin/flag-metadata data/gisaid/metadata.tsv > data/gisaid/flagged_metadata.txt
    ./bin/check-locations data/gisaid/metadata.tsv \
        data/gisaid/location_hierarchy.tsv \
        gisaid_epi_isl

    if [[ "$branch" == master ]]; then
        ./bin/notify-slack --upload "flagged-annotations" < "$flagged_annotations"
        # csv-diff runs out of memory
        #./bin/notify-on-metadata-change data/gisaid/metadata.tsv "$S3_SRC/metadata.tsv.gz" gisaid_epi_isl
        ./bin/notify-on-additional-info-change data/gisaid/additional_info.tsv "$S3_SRC/additional_info.tsv.gz"
        ./bin/notify-on-flagged-metadata-change data/gisaid/flagged_metadata.txt "$S3_SRC/flagged_metadata.txt.gz"
        ./bin/notify-on-location-hierarchy-addition data/gisaid/location_hierarchy.tsv source-data/location_hierarchy.tsv
    fi

    ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/metadata.tsv "$S3_DST/metadata.tsv.gz"
    ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/nextclade.tsv "$S3_DST/nextclade.tsv.gz"
    ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/additional_info.tsv "$S3_DST/additional_info.tsv.gz"
    ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/flagged_metadata.txt "$S3_DST/flagged_metadata.txt.gz"
    ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/sequences.fasta "$S3_DST/sequences.fasta.xz"

    if [ -f "data/gisaid/nextclade.aligned.fasta" ]; then
      ./bin/upload-to-s3 ${silent:+--quiet} data/gisaid/nextclade.aligned.fasta "$S3_DST/nextclade.aligned.fasta.xz"
    fi

    ./bin/clean

    if [[ "$fetch" == 1 && "$branch" == master ]]; then
        echo "Triggering ncov preprocessing GitHub action via repository dispatch."
        curl -fsS https://api.github.com/repos/nextstrain/ncov/dispatches \
          -H 'Accept: application/vnd.github.v3+json' \
          -H 'Content-Type: application/json' \
          -H "authorization: Bearer ${PAT_GITHUB_DISPATCH}" \
          -d '{"event_type":"preprocess-gisaid"}'
    else
        echo "Skipping running of ncov preprocessing workflow as the current branch is not master or we are running an ingest only (not a fetch-and-ingest)."
    fi
}

print-help() {
    # Print the help comments at the top of this file ($0)
    local line
    while read -r line; do
        if [[ $line =~ ^#! ]]; then
            continue
        elif [[ $line =~ ^# ]]; then
            line="${line/##/}"
            line="${line/# /}"
            echo "$line"
        else
            break
        fi
    done < "$0"
}

main "$@"
